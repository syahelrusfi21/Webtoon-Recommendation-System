# -*- coding: utf-8 -*-
"""Laporan Proyek Machine Learning - Sistem Rekomendasi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12uXl_GfHvWYbforMJ6GwF7FxobATvb4C

# **Laporan Proyek Machine Learning - Syahel Rusfi Razaba**
*Webtoon Recommender System*

## **Import Library**
Mengimpor semua library Python yang dibutuhkan untuk menjalankan proyek, seperti `pandas` untuk manipulasi data, `numpy` untuk operasi numerik, `re` untuk ekspresi reguler, `TfidfVectorizer` dan `cosine_similarity` dari `sklearn` untuk pembuatan model rekomendasi, serta `matplotlib` dan `seaborn` untuk visualisasi data.
"""

# Import Library
import pandas as pd
import numpy as np
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt
import seaborn as sns

# Library for text cleaning
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
# Download stopwords (only needed once)
nltk.download('stopwords')

"""## **Load Dataset**
Membaca dataset `Webtoon Dataset.csv` yang berisi data terkait informasi Webtoon. Dataset ini memiliki beberapa fitur seperti Name, Writer, Likes, Genre, Rating, Subscribers, Summary, Update, id, dan Reading Link.
"""

# Load Dataset
df = pd.read_csv('https://github.com/syahelrusfi21/Webtoon-Recommendation-System/raw/main/dataset/Webtoon%20Dataset.csv')
print("Dimesnsi data:", df.shape)
df.head()

"""## **Data Understanding**
Dataset yang digunakan adalah Webtoon Dataset yang diperoleh dari [Kaggle](https://www.kaggle.com/datasets/swarnimrai/webtoon-comics-dataset).
### Informasi Dataset:
- Jumlah sampel: 569 baris (sebelum cleaning)
- Jumlah fitur: 10 fitur input

### Fitur:
| Fitur | Deskripsi |
| ------ | ------ |
| id | ID unik yang mengidentifikasi komik. |
| Name | Nama lengkap komik. |
| Writer | Penulis komik. |
| Likes | Total jumlah Like. |
| Genre | Genre komik. |
| Rating | Rata-rata rating komik dari skala 10. |
| Subscribers | Total jumlah Subscriber. |
| Summary | Ringkasan komik. |
| Update | Hari dalam seminggu untuk update. |
| Reading Link | Tautan di mana komik dapat dibaca. |

## **Data Preparation**
Bagian utama untuk membersihkan dan menyiapkan data sebelum digunakan dalam tahap model development.

### **Data Cleaning**
Menghapus kolom yang tidak relevan (`id` dan `Reading Link`), memeriksa informasi dataset (`df.info()`), mengonversi kolom `Likes` dan `Subscribers` menjadi tipe data numerik dengan menangani akhiran 'K', 'M', dan 'B', memeriksa data duplikat, dan menangani missing value dengan menghapus baris yang memiliki missing value.
"""

# Drop irrelevant columns
df = df.drop(['id', 'Reading Link'], axis=1)
print("Kolom setelah dihapus:")
df.head()

# Dataset Information
print("Informasi Dataset:")
df.info()

def convert_to_numeric(value):
    """Converts a string representation of a number with K, M, or B suffixes to a numeric value,
       handling both comma and period as decimal separators, and commas as thousands separators."""
    value = str(value).strip().upper() # Convert to uppercase for consistent handling

    # Remove commas used as thousands separators
    value = value.replace(',', '')

    multiplier = 1
    if 'B' in value:
        value = value.replace('B', '')
        multiplier = 1_000_000_000
    elif 'M' in value:
        value = value.replace('M', '')
        multiplier = 1_000_000
    elif 'K' in value:
        value = value.replace('K', '')
        multiplier = 1_000

    try:
        # Use float() first to handle potential decimal points before converting to int
        return int(float(value) * multiplier)
    except ValueError:
        return 0 # Return 0 or NaN for values that can't be converted


df['Likes'] = df['Likes'].apply(convert_to_numeric).astype(int)
df['Subscribers'] = df['Subscribers'].apply(convert_to_numeric).astype(int)

print("Tipe data setelah konversi:")
print(df[['Likes', 'Subscribers']].dtypes)
df.head()

# Check for duplicate data
print("Jumlah data duplikat:", df.duplicated().sum())

# Check for missing values
print("Jumlah missing value per kolom:")
print(df.isnull().sum())
print("Dimesnsi data:", df.shape)

# Remove missing values
df.dropna(inplace=True)
df.reset_index(drop=True, inplace=True)
print("Jumlah missing value setelah dihapus:")
print(df.isnull().sum())
print("Dimesnsi data:", df.shape)

"""### **Exploratory Data Analysis**
Pada tahap ini, akan dieksplorasi terkait distribusi dan karakteristik data, seperti ringkasan statistik kolom numerik, distribusi Webtoon berdasarkan Genre, Distribusi Webtoon berdasarkan Jadwal Update, dan visualisasi outlier menggunakan Boxplot.
"""

# Summary of descriptive statistics
print("Ringkasan Statistik Kolom Numerik:")
display(df[['Likes', 'Rating', 'Subscribers']].describe())

# Distribution of Genre
plt.figure(figsize=(12, 6))
sns.countplot(data=df, y='Genre', order=df['Genre'].value_counts().index, color='steelblue')
plt.title('Distribusi Webtoon berdasarkan Genre')
plt.xlabel('Jumlah Webtoon')
plt.ylabel('Genre')
plt.show()

"""Dari plot distribusi `Genre`, terlihat bahwa:

- Genre Fantasy, Romance, dan Drama memiliki jumlah Webtoon (komik) paling banyak berdasarkan sampel data dalam proyek ini. Hal ini
mengindikasikan bahwa genre tersebut memang banyak ditulis oleh para author. Bisa jadi hal ini karena cerita bergenre fantasy, romance, atau drama lebih laku di pasaran, memiliki peminat yang tinggi, atau jalan ceritanya cenderung lebih ringan ketimbang genre lainnya, sehingga lebih banyak author yang memilih untuk menulis cerita-cerita tersebut.
- Lalu genre seperti historical dan informative, cenderung sedikit jumlah komiknya. Ini menguatkan asumsi saya kalau memang jalan cerita terkait genre ini cenderung lebih sulit dan perlu fokus dan riset mendalam selama penulisannya.
"""

# Distribution of Update
plt.figure(figsize=(10, 6))
sns.countplot(data=df, y='Update', order=df['Update'].value_counts().index, color='seagreen') # Using a single color
plt.title('Distribusi Webtoon berdasarkan Jadwal Update')
plt.xlabel('Jumlah Webtoon')
plt.ylabel('Jadwal Update')
plt.show()

"""Berdasarkan distribusi `Update`, sebagian besar komik Webtoon dari sampel dataset ini merupakan komik yang sudah selesai (*completed*). Selain itu, komik yang masih berlanjut (*ongoing*) rata-rata update per-minggu seperti tiap hari Jumat, Rabu, atau Sabtu. Lalu, ada yang menarik juga bahwa ternyata ada komik yang updatenya cukup sering, yakni setiap hari Senin, Selasa, Rabu, Kamis, dan Minggu, namun jumlahnya hanya sedikit."""

# Distribution of numerical columns
numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns

plt.figure(figsize=(15, 10))
for i, col in enumerate(numerical_cols):
    plt.subplot(2, 4, i + 1) # Adjust the grid based on the number of numerical columns
    sns.boxplot(y=df[col])
    plt.title(f'Boxplot of {col}')
plt.tight_layout()
plt.show()

"""Terlihat bahwa distribusi data numerik tidak terdistribusi secara normal (cenderung skewed) dan terdapat banyak outlier. Untuk menangani outlier ini, kita akan menggunakan metode transformasi yang dikenal sebagai **Winsorization** (atau Capping).

Dengan metode ini, nilai-nilai ekstrem (outlier) tidak dihapus, melainkan dibatasi atau "dicapping". Nilai-nilai yang berada di atas batas atas (Q3 + 1.5 * IQR) akan diganti dengan nilai batas atas tersebut, sementara nilai-nilai yang berada di bawah batas bawah (Q1 - 1.5 * IQR) akan diganti dengan nilai batas bawah.

Pendekatan Winsorization dipilih untuk mempertahankan jumlah data asli sambil mengurangi pengaruh nilai-nilai yang sangat ekstrem pada analisis dan model.

### **Data Pre-Processing**
Pada tahap ini, akan dilakukan transformasi data variabel numerik menggunakan **Winsorization** untuk menangani outlier.
"""

# Copy original data
df_transformed = df.copy()

# List numerical features (extract all numeric columns from df_transformed)
numerical_features = df_transformed.select_dtypes(include=np.number).columns

# Winsorization: Limit outlier values to IQR boundaries
for col in numerical_features:
    Q1 = df_transformed[col].quantile(0.25)
    Q3 = df_transformed[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    df_transformed[col] = np.where(df_transformed[col] < lower_bound, lower_bound,
                            np.where(df_transformed[col] > upper_bound, upper_bound, df_transformed[col]))

df_transformed.head()

# Outlier visualization with Boxplot after transformation
numerical_cols_transformed = df_transformed.select_dtypes(include=['float64', 'int64']).columns

plt.figure(figsize=(15, 10))
for i, col in enumerate(numerical_cols_transformed):
    plt.subplot(2, 4, i + 1) # Adjust the grid based on the number of numerical columns
    sns.boxplot(y=df_transformed[col])
    plt.title(f'Boxplot of {col}')
plt.tight_layout()
plt.show()

"""Setelah proses transformasi, terlihat bahwa outlier telah berhasil dihilangkan. Oleh karena itu, dataset ini sudah cukup bersih untuk digunakan dalam tahap modeling atau analisis lanjutan. Namun, dalam proyek ini, karena akan menerapkan pendekatan **Content-Based Filtering**, dataset asli sebelum transformasi tetap digunakan. Hal ini dikarenakan hanya kolom `Summary`, `Genre`, dan `Name` (judul Webtoon) yang akan dimanfaatkan dalam sistem rekomendasi.

Text pre-processing
"""

# Combine summary and genre
df['Content'] = df['Summary'] + ' ' + df['Genre']

# Initialize stopwords and stemmer
stop_words = set(stopwords.words('english'))
stemmer = PorterStemmer()

# Complete text preprocessing function
def clean_text(text):
    text = text.lower()  # convert to lowercase
    text = re.sub(r'[^a-z\s]', '', text)  # remove punctuation and numbers
    words = text.split()  # tokenize

    # remove stopwords and apply stemming
    words = [stemmer.stem(word) for word in words if word not in stop_words]

    return ' '.join(words)

# Apply the preprocessing to the dataset
df['Content_Clean'] = df['Content'].apply(clean_text)

"""Vektorisasi dengan TF-IDF"""

# Initialize vectorizer and create TF-IDF matrix
vectorizer = TfidfVectorizer(stop_words='english')
tfidf_matrix = vectorizer.fit_transform(df['Content_Clean'])

# Compute cosine similarity between all webtoons
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

# Create a quick search index from titles
indices = pd.Series(df.index, index=df['Name'].str.lower())

"""## **Model Development dengan Content-Based Filtering**
Pada tahap ini, akan dibuat sistem rekomendasi berbasis konten, yakni berdasarkan genre dan ringkasan komik.
"""

# Recommendation system function with cosine similarity score

def recommend_webtoons(title, top_n=5):
    title_lower = title.lower()

    # Check if the title exists in the index
    if title_lower not in indices:
        return f"Webtoon '{title}' tidak ditemukan."

    idx = indices[title_lower]

    # Calculate similarity scores and sort them
    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # Extract top N recommendations (skip the first one because it's the input itself)
    top_sim_scores = sim_scores[1:top_n+1]
    webtoon_indices = [i[0] for i in top_sim_scores]
    similarity_values = [i[1] for i in top_sim_scores]

    # Data of the searched title
    input_webtoon = df.iloc[[idx]][['Name', 'Genre', 'Summary']].copy()
    input_webtoon['Keterangan'] = 'Judul yang dicari'
    input_webtoon['Similarity'] = 1.0  # Similarity terhadap dirinya sendiri = 1

    # Recommended webtoons data
    recommended = df.iloc[webtoon_indices][['Name', 'Genre', 'Summary']].copy()
    recommended['Keterangan'] = 'Rekomendasi'
    recommended['Similarity'] = similarity_values

    # Combine results
    result = pd.concat([input_webtoon, recommended], ignore_index=True)

    # Optional: Urutkan kembali berdasarkan skor similarity jika diperlukan
    result = result.sort_values(by='Similarity', ascending=False).reset_index(drop=True)

    return result

# Apply the Webtoon Recommendation System
recommend_webtoons("Lookism", top_n=5)

"""## **Evaluation**

Sistem rekomendasi ini menggunakan pendekatan **Content-Based Filtering** dengan menggabungkan fitur `Genre` dan `Summary` dari setiap Webtoon, yang kemudian direpresentasikan sebagai vektor menggunakan teknik **TF-IDF (Term Frequency-Inverse Document Frequency)**. Untuk menghitung kemiripan antar Webtoon, digunakan metrik **Cosine Similarity**:

$$
\text{Cosine Similarity}(A, B) = \frac{A \cdot B}{\|A\| \times \|B\|}
$$

Cosine Similarity bernilai antara 0 hingga 1. Semakin mendekati 1 berarti semakin mirip kontennya. Namun dalam praktiknya, terutama pada data teks seperti sinopsis Webtoon, nilai similarity sering kali kecil (< 0.2). Ini **bukan kesalahan**, melainkan sifat alami dari representasi teks yang kompleks dan bervariasi.

Karena tidak tersedia data interaksi pengguna, maka evaluasi dilakukan secara **kualitatif**. Untuk menilai apakah hasil rekomendasi memang relevan, kita ambil contoh:

### Contoh Pencarian: *Lookism*

**Judul Input:**
- **Lookism** (Genre: Drama)  
  _Daniel is an unattractive loner who wakes up in a different body. Now tall, handsome, and cooler than ever in his new form, Daniel aims to achieve everything he couldn't before. How far will he go to keep his body... and his secrets?_

**Rekomendasi 1:**
- **Fluidum** (Genre: Drama)  
  _Jesse was born like every citizen in the Fluidum universe, spending their first 20 years shifting seamlessly between a male and female body. Now with only one year left until they must choose one body for the rest of their life, Jesse is questioning the unquestionable... why decide at all?_

**Rekomendasi 2:**
- **My Life as a Loser** (Genre: Drama)  
  _My life was ruined after you bullied me in high school. So why do you get to be happy and successful? I'll give you a taste of your own medicine! Now you'll see what it felt like to be me... And you better be ready to pay the price if you want to return to your own body._

Dari ringkasan di atas, terlihat bahwa sistem berhasil merekomendasikan Webtoon dengan **tema yang senada**, seperti transformasi hidup, tekanan sosial, dan kehidupan sekolah. Hal ini menunjukkan bahwa sistem mampu mengidentifikasi kesamaan konten meskipun similarity score secara numerik kecil.

### Kesimpulan
- Pendekatan *content-based filtering* terbukti mampu memberikan rekomendasi Webtoon yang relevan berdasarkan kesamaan konten, khususnya genre dan ringkasan cerita.
- Meskipun nilai *cosine similarity* tergolong rendah, metrik ini tetap efektif karena fokus utamanya adalah pada urutan kemiripan relatif antar judul.
- Evaluasi secara kualitatif dapat memperkuat keabsahan sistem meski tanpa data eksplisit pengguna.

"""